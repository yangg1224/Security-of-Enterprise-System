---
title: "Are iPhone users more secure when using mobile enterprise systems?"
subtitle: "The difference of the perceived security of Enterprise Systems between IOS and Android users"
author: "Yang Wu"
header-includes:
 - \usepackage{float}
 - \floatplacement{figure}{H}
 - \floatplacement{table}{H}
thanks: "Code and data are available at: https://github.com/yangg1224/Security-of-Enterprise-System.git."
date: "`r format(Sys.time(), '%d %B %Y')`"
abstract: "Organizations are adopting mobile technologies for various business applications including Enterprise system (ES) to increase the flexibility and to gain sustainable competitive advantage. At the same time, end-users are exposed to security issues when using mobile technologies. Users’ usage habits and users’ attitudes towards those potential security issues would have a significant impact to the perceived security of ES. Here comes the question: will iPhone users have higher perceived security than Android users? Through the propensity score matching and regression model, we have the answer. \\par \\textbf{Keywords:} Security Issues; Perceived security measurement; iPhone & Android; Matching "

output:
  bookdown::pdf_document2:
toc: TRUE
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tinytex)
library(tidyverse)
library(palmerpenguins)
library(ggplot2)
library(ggthemes)
library(ggpubr)
library(hrbrthemes)
library(kableExtra)
library(broom)
library(randomForest)
library(plyr)
library(qqplotr)
library(dplyr)
library(gridExtra)
```

# Introduction
Mobile Enterprise System (ES) has more unique advantages than traditional enterprise systems. With a mobile enterprise platform, the entire company can be moved to the internet. Therefore, users who have permission can remotely access the enterprise database with any device equipped with a browser. Easy and convenient accessibility of data from mobile devices anywhere and anytime has made a significant change in people’s working style [@al2011preliminary]. People are no longer confined to working in the office, and any place can be their workstation. Besides, increasing business applications take advantage of mobile devices features such as a touchscreen, camera, video, voice, and other advanced functions to maximize the productivity. [@rodrigues2021mediation].


These advantages have created a vulnerability. The primary design purpose for the mobile device is its portability, not its security, which gives mobile enterprise systems weaker defense capabilities (He, 2013). There are many challenges and issues stemming from a lack of users’ awareness and negative attitudes. It is increasingly hard for an enterprise to maintain resource safety since the interaction between the user and device boost sharply. The features of these interactions are often unplanned and lack of supervision, which makes the leakages of the enterprise information possible[@matkerimov2020ways].


The dependent variable in my project is the perceived security of mobile ES. Many researchers have widely discussed the definition of mobile ERP system security. Although their understanding of the ERP security is strongly based on their speciﬁc domains, some aspects of the understanding of mobile ERP security are shared. [@siponen2007review] define security as the protection of resources to attain the objectives of integrity, availability, and conﬁdentiality. With regards to “integrity”, the authors suggest the metadata cannot be modified without authorization, while “availability” means that authorized person can access information anytime and anywhere. Finally, “confidentiality” refers to certain actions being implemented to prevent information leakage.


As we all know, compared with Android devices, iPhone has relatively closed platform, which gives it higher security performance. But users’ usage habits also have a huge impact towards the perceived security. For example, if users tend to use public Wi-Fi at coffee shop, the perceived security of ES would be lower. Because the system has more risk of information leakage. (whether they update operating system; how they deal with pop up security warning ...) All those uncertainties raise my interest to figure it out.  


The purpose of this project is to examine whether iPhone users (IOS) are securer than Android users when using mobile ES. The intervention is using iPhone as mobile device. The questionnaire survey is the chosen method for collecting data from mobile ES users, which has been done last year.  **propensity score matching** will be used to avoid selection bias and evaluate the effect of the treatment by comparing the treaded and non-treated group. It allows me to easily consider many independent variables at once, and it can be constructed using logistic regression. Multiple regression will also be used to examine the impact of users’ attitudes towards perceived ES security. The research finding will help the security providers of ES to know the determinants of perceived security in the users’ perspectives and to take measures to improve the determinants.


The remainder of the paper is constructed as follows. Section 2 describes the dataset, data collection, and exploratory data analysis on feature visualization. Section 3 outlines the data analysis models, which is designed to discover relationships between features and the target variable. Section 4 summarizes the model results according to evaluation criteria. Finally, Section 5 discusses the research findings and provides directions for future research.


This paper uses R statistical programming language [@citeR]. In particular, we use packages `tidyverse` [@tidyverse],  `here` [@citehere], `ggpubr` [@citeggpubr] to manipulate data and packages, `kableExtra` [@citekableExtra] to generate tables, and `ggplot2` [@citeggplot], `ggthemes` [@citeggthemes] to adjust diagrams themes. 

# Data

## Intervention 

To accomplish the research objectives, the author did a literature review on perceived security of mobile Enterprise System (ES). Based on the current research findings, the author concludes that there are five main categories of security issues when using mobile ES, which are mobile device issues, wireless network issues, cloud computing issues, application-level issues, and data access level issues. Different mobile phone users would have different attitudes and usage habits towards those five areas security issues, which greatly affect the perceived security of the ES. In order to test how different those impact on the iPhone and Android users, the author plan to divide people into two groups. The intervention of this research is using iPhone as mobile device. The treated group will be people who use iPhone (IOS) to operate the ES, and people in the control group will be those who use Android (Huawei, Samsung, Mi, and so on).

## Data collection

An online questionnaire survey is the chosen method for collecting data from Mobile ES users. Compared with other methods, the major advantages of the online questionnaire are saving time, money, and manpower. Considering this research need to do a large quantity of data collection, the questionnaire is the only suitable method. The author conducted the online questionnaire survey one year ago under the guidance of the research method class. 


Through the agency of Chinese online questionnaire platform ‘Wenjuan Xing’ and the researcher’s personal relationship with certain companies, the author sends out around 800 online questionnaires randomly and 240 personal administered questionnaires. The personally administered survey is useful to increase the response rate and to enhance the data quality. The email reminders were sent for every ten days to encourage the potential participants to fill in their responses. 

## Questionnaire design and sample

The respondents were asked to do a demographics survey which includes age, gender, occupation, years of experience, name of the ES systems used, functions or modules of Mobile ES, Brand of the mobile devices used to access the ES, and ownership of the device. The questionnaire also has items for measuring users’ attitudes and usage habits on various security issues and perceived security of ES mobility. The data features part will describe more about it.  The data was collected by using an interval scale (0-strongly disagree to 10-strongly agree). The collected data was used for calculating the measures of central tendency (e.g. arithmetic mean), validating the hypotheses by using correlation, propensity score matching, multiple regression and other statistical analysis. 


By the end of the survey period, data had been collected from 344 participants. As a result, the overall response rate is 33%. Among 344 responses, 13 responses were rejected on account of too much missing data. Therefore, 331 useable online questionnaire data were obtained and used for data analysis. 

The screen shots of the questionnaire will be attached in the Appendix 1. 


## Dataset features

### Demographics features
Overall, the dataset has 331 observations and contains 50 features. The first nine features describes users' demographic information. 

* `Work_experience` : measures how long does the user work in the current company 
* `Gender` : describes the user's gender 
* `Age` : describes the user's age
* `Education_level` : describes user's educational level (High school, college, undergrad, postgrade) 
* `Functions_used` : asks users which functionalities they use everyday
* `Usage_frequency` : describes the frequency of the usage of mobile ES
* `ES_Name` : describes the name of ES
* `Mobile_device` : asks for user's mobile phone brand 
* `Device_ownership` : clarify if the mobile phone is owned by company or owned by the user 

### perceived ES security features [reference!!!]

The perceived ES security is this paper's dependent variable. According to Levent et al. (2005), enterprise security plan serves as an essential role to coordinate information security policies and applicable security technologies, making them align with the business rules and the developing information models and technical architectures. Consoli (2012) combined acknowledged definitions of context and security, and concluded the security context should point to five goals:Integrity to ensure that data is in the original format and not modified; Confidentiality to ensure that only authorized people have access to resources; Authentication for allowing the access to the resources; Availability to maintain the proper functioning of the information system; Non-repudiation to ensure that a transaction cannot be denied.

According to the definition above, the dataset has five features to measure the perceived ES security. Starting from here, the questionnaire is designed using interval scale (0-strongly disagree to 10-strongly agree). The user is asked to give a number between 0 and 10, which represent for their attitudes towards the given situation. 

* `system_integrity` : measures user's attitude towards "I believe the data/ information in the mobile enterprise systems cannot be modified by unauthorized users"
* `system_availability` : measures user's attitude towards "I believe the data/ information in the mobile enterprise systems is available only to authorized users when required "
* `system_confidentiality` : measures user's attitude towards "I believe that the mobile enterprise systems are secured as the system detects and prevents the improper disclosure/ leakage of information"
* `system_accountability` : measures user's attitude towards "I believe that the mobile enterprise systems are secured as the system accounts the data changes"
* `system_nonrepudiation` : measures user's attitude towards "I believe that the mobile enterprise system is secured as the system does not deny any transaction that was carried out"
* `PSave` : (Dependent variable) used in the model. It takes a mean of the previous five features and presents for the user's perceived ES security. 

### Molibe device security issue features [references!!!]

A mobile device refers to any portable device which has computing and storage capabilities(Singh & Ranjan, 2016). The range of devices from smartphones, iPads, and tablets is quite popular among clients and IT professionals. Mobile users can work everywhere without being constrained by any networking system. These mobility and roaming features extend the network boundary beyond a single fixed point but make security management a much harder issue, because users cannot be tracked down into a fixed location anymore (Al Ladan, 2016). Moreover, mobile devices’ operational systems are highly vulnerable, which results in threats having a variety of ways to spread. There is no device whose platform is completely closed, which has weakened the security performance of the original application and creates more risks for information sharing (Hermann & Fabian, 2014).  There are six independent variables which might affect the perceived ES security:

* `Install_firewall` : measures user's attitude towards " I feel painful to install or update the security software such as antivirus and firewall software on my device."
* `BYOD` : measures user's attitude towards " I like the idea of using my own device for personal and corporate business."
* `Ignore_warnning` : measures user's attitude towards " I like to install applications in my mobile device without paying attention to permission warnings (or terms and conditions of usage)."
* `Strong_pin` : measures user's attitude towards " I feel painful to use a password or a pin code to lock my mobile device."
* `Store_passwords` : measures user's attitude towards " I feel it is simple and easy to store usernames and passwords on the device."
* `update_OS` :measures user's attitude towards " I feel painful to update the operating systems (e.g. iOS, Android) in my mobile device. "

### Wireless network security issue features [reference!!!]

Mobile communication is generated mainly through radio signals rather than wires, so mobile ES has particular challenges compared with traditional computer-based ES. First of all, reliable Internet availability is a pre-requirement for the secure wireless network. According to Hermann and Fabian (2014), “the wireless network is more accessible to intercept and attack, so traditional security technologies such as firewalls, authentication servers, biometrics, cryptography, intrusion detection, and VPNs are not enough to address security issues in the wireless network”(Hermann & Fabian, 2014). There are six independent variables related to the wireless network which might affect the perceived ES security:

* `public_WiFi` : measures user's attitude towards "  I believe it is secured to use the wireless networks in public places such as coffee shops, airport kiosks, or other hotspots"
* `unsecured_network` : measures user's attitude towards " I show no interest on the security threats on the wireless networks."
* `network_control` : measures user's attitude towards " I feel nervous to know the enterprise doesn’t have much security control over the wireless networks."
* `network_attack` : measures user's attitude towards " I feel nervous to know that the hacker needs only a mobile device and a wireless card to capture data packets and transmission of the data."
* `encrypted_transimittion` : measures user's attitude towards " I believe the wireless network is not secured enough when the transmitted information is not encrypted."
* `unreliable_int` :measures user's attitude towards " I believe the data security and protection may be compromised when the Internet connection is not available and reliable. "

### Cloud Computing Security Issue features

The appearance of cloud computing is narrowing down the gap between mobile ES and small to medium companies. Although it does cut down the set-up process time and cost and reduces the required skills in the company, some challenges and problems should still be kept in mind. Certain loopholes in its architecture have made cloud computing vulnerable to various security and privacy threats (Picek, Mijac, & Androcec, 2017).There are six independent variables related to the cloud computing which might affect the perceived ES security:

* `cloud_resource` : measures user's attitude towards "I believe that the applications that use cloud resources are vulnerable to threats."
* `cloud_compute` : measures user's attitude towards "I believe the cloud computing is vulnerable for data security since the access can be
interrupted at multiple points in the cloud."
* `remote_datastore` : measures user's attitude towards "Since the data is stored and processed remotely in cloud computing, I believe that the true ownership of the data becomes a security issue."
* `Data_regulation` : measures user's attitude towards "Since the data can be located anywhere in the world with different control and privacy regulations, I believe this practice leads to security risks."
* `multiple_login` : measures user's attitude towards " In a cloud environment, I like to logon to the same application using multiple devices simultaneously."
* `weak_authentication` :measures user's attitude towards "In a cloud environment, I like to use simple and short passwords."

### Application level security issue features
The application-level mobile solution mainly consists of mobile operation systems and mobile applications. The application layer provides users with an interface to operate their mobile devices. The operation system act as a platform to run mobile applications. Application-level issues usually take place in a multi-tenant environment or in a virtualized world. There are six independent variables related to the application which might affect the perceived ES security:

* `unknown_app` : measures user's attitude towards "I feel pleasant to download applications from unreliable web sites or from links within e-mails"
* `update_ES` : measures user's attitude towards "I believe in installing updates for ERP systems to avoid any outdated security protections."
* `Auto_update` : measures user's attitude towards " I like to use automatic updater which applies any software application updates whenever available."
* `VPN` : measures user's attitude towards "I like to use VPN connections to download applications"
* `third_party_app` : measures user's attitude towards " I believe more fake apps/ malware versions (for Android) are found on third-party
application sites."
* `update` :measures user's attitude towards "I like to update the device operating systems and applications when prompted."

### Data Level Security Issue features
Since there is currently no appropriate regulation around data protection, data-level security is relying heavily on trust between the business and the provider. Data location and replication is one of the biggest concerns in the data level. A replica might be located in different countries where there is no clear legislation about data security and privacy, increasing the difficulty of managing the data (Kouatli, 2014). There are six independent variables related to the data access which might affect the perceived ES security:

* ` single_authenticate` : measures user's attitude towards "I like single authentication process for data access using only passwords."
* `audit_log` : measures user's attitude towards "I dislike maintaining audit logs to track any changes in the data.."
* `access_right` : measures user's attitude towards "I feel comfortable to give access rights to access all information to all employees"
* `change_data` : measures user's attitude towards " I feel comfortable to give permission to change all information by all employees"
* `malicious_attack` : measures user's attitude towards " I believe hackers can harvest user information from mobile ES and create malicious content to fraud the individual user"
* `Data_threat` :measures user's attitude towards "I believe anytime and anywhere data access with ES mobility brings a large number of data security threats."

## Descriptive Analysis 
```{r ,echo=FALSE}
####read the clean data 
clean_data<- read.csv(here::here("inputs/DATA/processed_dataset.csv"))
```


### Treat distribution 
From Figure \@ref(fig:treat) , we can clearly see that the iPhone user takes the lead and follows by HuaWei phone’s user. One reason why iPhone is so popular is that The iPhone ensures all apps and functions are performing the way Apple intended them to perform, which allows for a very simple user experience. As we know, iPhone devices use IOS operation system, while other type of devices are mostly using Android operation system. So the the author category all the users into two groups, one is using IOS and the other one is using Android. The second graph shows a balanced state between all the respondents. 

```{r treat, fig.cap = "device used by the respondents",echo=FALSE, warning= FALSE,fig.width=10, fig.height=6}

EDA<-clean_data

device_map <- 
  EDA%>%
  ggplot(aes(x = Mobile_device, fill = Mobile_device)) +
  geom_bar(width = 0.7,position = "dodge") + 
  coord_polar()+
  labs(title = "Device used by the respondents",x="", y="Count") +
  theme_minimal()

EDA$treat<-sapply(EDA$treat, as.character)

# Create treat map data.
#table(EDA$treat)
data <- data.frame(
  category=c("treat(IOS)", "control(Android)"),
  count=c(163, 168)
)

# Compute percentages
data$fraction <- data$count / sum(data$count)

# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)

# Compute the bottom of each rectangle
data$ymin <- c(0, head(data$ymax, n=-1))

# Compute label position
data$labelPosition <- (data$ymax + data$ymin) / 2

# Compute a good label
data$label <- paste0(data$category, "\n value: ", data$count)

# Make the plot
treat_map<-
  ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=category)) +
  geom_rect() +
  geom_label( x=3.5, aes(y=labelPosition, label=label), size=6) +
  scale_fill_brewer(palette=1) +
  coord_polar(theta="y") +
  xlim(c(2, 4)) +
  theme_void() +
  theme(legend.position = "none")

# combine two diagram in one graph
ggarrange(
  device_map, treat_map,
  ncol = 2, nrow = 1,
  hjust = -0.5,
  align = "hv"
  )
```



### Demographics of user's work experience
Figure \@ref(fig:workexperience) demonstrates questionnaire respondents' work experience between treat group and control group. The red histogram represents people who use Android and the yellow histogram stands for iPhone users group. Working experience is an important element which might affect users' usage habits. The more professional they are, the more knowledge and experience they would have. Overall, we can see a relatively balanced match between iPhone and Android users. Most participants are holding three to five years working experience. It is interesting to find participants who has less than one year working experience like to use iPhone, while those with more than six year experience prefer to use Android. In terms of consistency, every iPhone works the same, while every Android works differently. Maybe more professional people would like to customize their phone and have more power to control their device. 


```{r workexperience, fig.cap = "Demographics of user's work experience",echo=FALSE, warning=FALSE,fig.width=10, fig.height=4}
edu <- 
  EDA%>%
  ggplot(aes(x = Work_experience,fill=treat, )) +
  geom_bar(position="dodge") +
  labs(title = "Demographics of user's work experience between treat and control group",x= "Work experience", y="Count")+
  scale_fill_manual(name = "Treat Group",values = c("#DB7558", "#FFCF57"))
edu
```

### Education level between treat and control group

Figure \@ref(fig:education) uses the jitter plot to visualize the distribution of education level by intervention groups. As we can see from the chart, people’s educational level is approximately at undergraduate and college. The iPhone user group is slightly more than Android user group in Master degree. But in general, there is not too much difference in terms of two group's educational level. 

```{r education, fig.cap = "Education level between treat and control group",echo=FALSE, fig.width=6, fig.height=3}

s1<-
  ggplot(EDA, aes(x = treat, y= Education_level,color=treat)) +
  geom_point(position = "jitter", alpha = 4/5)+
  labs(title="Education level between treat and control group", x="Intervention", y="Education level")+
  theme_light() + 
  scale_color_manual(name = "Treat group", values = c("#DB7558", "#FFCF57")) 
s1
```


### Device ownership 

Device ownership also plays an important role in security context.  Many employees bring their own device to the company for work and personal usage (bring your own device, BYOD), which is not trustworthy for enterprise system security [@souppaya2013guidelines]. As company has less control over employees’ device, they have rights to download any software or choose the security level of their mobile devices. Figure \@ref(fig:own) shows who own the device among 331 observations. We can find almost 95% devices are owned by the participants themselves. 

```{r own, fig.cap = "internet usages",echo=FALSE, fig.width=6.5, fig.height=4}
G1<-ggplot(EDA, aes(x=Device_ownership, fill=Device_ownership))+ 
    geom_bar(alpha=0.8 , size=0.2, colour="black", stat = "count")+
    labs(title = "User's Device ownership ",y="Counts",x="")

G1
```




# Model

The author made a choice between difference in difference method and propensity score matching method. Both methods are good for analyze observation data. The difference-in-difference method captures the significant differences in outcomes across the treatment and control groups, which occur between pre-treatment and post-treatment periods[@lechner2011estimation]. Difference in differences is a useful analysis framework to compare the changes in dependent variables, but in this project, it is hard to identify a certain time period. Because we cannot force our survey participants to use certain mobile devices in this period. Besides that, there might be a huge selection bias if we use DD method. Between iPhone and Android users, there would have lots of difference like their education level, age, gender, work experience and so on. It is really hard to match the people in the treat and control groups as closely as possible. Therefore, the author choose to use propensity score matching in this project.

## propensity score matching method

Propensity score matching estimators are widely used in evaluation research to estimate average treatment effects[@abadie2016matching]. Propensity score matching creates a group of participants for the treatment and control groups. The matching group consists of at least one participant in the treatment group with similar propensity scores and at least one participant in the control group. The goal is to approximate a random experiment and eliminate many problems caused by observational data analysis like selections bias.

## propensity score estimation 

Basically, the propensity score matching method would assign some probability to each observation. In this project, based on the independent variables (users’ attitudes towards different kind of security issues), the author constructs the propensity score estimation. We estimate the propensity score by running a logit model where the dependent variable (perceived ES security) is a binary variable indicating treatment status. **glm()** is used to fit generalized linear models, specified by giving a symbolic description of the linear predictor and a description of the error distribution[@glm]. Table \@ref(tab:pse) shows the results. We can then compare the outcomes of observations with similar propensity scores. 


```{r pse, fig.cap = "propensity score estimation table",echo=FALSE}

m_ps<-glm(treat~ Install_firewall+BYOD+ Ignore_warnning+Strong_pin+ Store_passwords+update_OS+public_WiFi+unsecured_network+ network_control+network_attack+encrypted_transimittion+unreliable_int+cloud_resource +cloud_compute+remote_datastore+Data_regulation+multiple_login+weak_authentication+unknown_app+ update_ES+ Auto_update+VPN + third_party_app+update+single_authenticate+audit_log+access_right+ change_data+ malicious_attack+Data_threats, 
family = binomial(), data = clean_data)

library(modelsummary)
ms<-
modelsummary(
m_ps,
output = "default",
fmt = 3,
estimate = "estimate",
statistic = "std.error",
vcov = NULL,
conf_level = 0.95, #confidence level to use for confidence intervals
stars = TRUE,
align = NULL,
notes = NULL,
title = "propensity score estimation table")
ms%>%
  kableExtra::kable_styling(bootstrap_options = "basic",
                            latex_options = "HOLD_position",
                            table.envir = "table",
                            font_size =5
                          )


```


Using this model, we can now calculate the propensity score for each ES user. It is simply the user’s predicted probability of being Treated, given the estimates from the logit model. Below, the author calculates this propensity score using **predict()** and create a dataframe that has the propensity score as well as the user’s actual treatment status. Table \@ref(tab:ps)  shows the first 6 rows of result. 
```{r ps, fig.cap = "ES user's propensity score",echo=FALSE }
##propensity score 
prs_df <- data.frame(pr_score = predict(m_ps, type = "response"),
                     treat = m_ps$model$treat)
m<-head(prs_df)

m%>%
  kableExtra::kbl(caption="ES user's propensity score and actual treatment status")%>%
  kableExtra::kable_styling(latex_options = c("hold_position"))
```

## Examing the Region of common support
After estimating the propensity score, it is useful to plot histograms of the estimated propensity scores by treatment status. As shown in Figure \@ref(fig:cs1), these graphics show the overlap of the propensity scores of the two groups, suggesting they share a lot of common support on the covariates in the model.

```{r cs1, fig.cap = "ES user's propensity score",echo=FALSE, warning=FALSE,fig.width=6.5, fig.height=4}


labs <- paste("Actual phone type used:", c("IOS", "Andriod"))
prs_df %>%
  mutate(treat = ifelse(treat == 1, labs[1], labs[2])) %>%
  ggplot(aes(x = pr_score)) +
  geom_histogram(color = "white", bins=30) +
  facet_wrap(~treat) +
  xlab("Probability of using iPhone to operate ES") +
  theme_bw()

```

Common support Figure \@ref(fig:cs2) indicates the regions of stratification share enough members of the treatment and control groups.

```{r cs2, fig.cap = "ES user's propensity score",echo=FALSE, warning=FALSE,fig.width=6.5, fig.height=4}


prs_df %>%
  mutate(treat = ifelse(treat == 1, labs[1], labs[2])) %>%
  ggplot()+
  geom_histogram(aes(x=pr_score, y=..density.., fill=treat), color="white", bins=30, position="identity", alpha=.3)+
  geom_density(aes(x=pr_score, color=treat))

```

## Executing matching algorithm 
**MatchIt** package [@match] is used here to find pairs of observations that have very similar propensity scores, but that differ in their treatment status. This package estimates the propensity score in the background and then matches observations based on the "nearest" method.

Note that the final dataset is smaller than the original: it contains 326 observations, meaning that 163 pairs of treated and control observations were matched. Also note that the final dataset contains a variable called distance, which is the propensity score.
```{r  ema, fig.cap = "ES user's propensity score",echo=FALSE, warning=FALSE,fig.width=6.5, fig.height=4}
library(MatchIt)
mod_match <- matchit(treat~ Install_firewall+BYOD+ Ignore_warnning+Strong_pin+
                       Store_passwords+update_OS+public_WiFi+unsecured_network+
                       network_control+network_attack+encrypted_transimittion+unreliable_int+
                       cloud_resource +cloud_compute+remote_datastore+Data_regulation+multiple_login+
                       weak_authentication+unknown_app+  update_ES+ Auto_update+
                       VPN + third_party_app+update+single_authenticate+audit_log+access_right+ change_data+ malicious_attack +Data_threats, method = "nearest", data = clean_data)

## check the match
dta_m <- match.data(mod_match)
dim(dta_m)

head(dta_m)%>%
  kableExtra::kbl(caption = "T test: Affect level of video vs control")%>%
  kableExtra::kable_styling(latex_options = "scale_down")%>% # use scale_down option to make the font
  kableExtra::kable_styling(latex_options = c("hold_position"))
```

## Examining covariate balance in the matched sample

The author uses visualization to show whether the matching is done well. The Figure \@ref(fig:balance) plots the mean of each independent variable against the estimated propensity score, separately by treatment status. If the matching result is good, the treatment and control groups will have similar identical means of each covariate at each value of the propensity score. In general, the model has a good match. 

```{r balance, fig.cap = "covariate balance check",echo=FALSE, warning=FALSE,fig.width=8, fig.height=10}

fn_bal <- function(dta, variable) {
  dta$variable <- dta[, variable]
  dta$treat <- as.factor(dta$treat)
  support <- c(min(dta$variable), max(dta$variable))
  ggplot(dta, aes(x = distance, y = variable, color = treat)) +
    geom_point(alpha = 0.2, size = 1.3) +
    geom_smooth(method = "loess", se = F,formula = y ~ x) +
    xlab("Propensity score") +
    ylab(variable) +
    theme_bw() +
    ylim(support)
}

 grid.arrange(
   fn_bal(dta_m, "Install_firewall")+ theme(legend.position = "none"),
   fn_bal(dta_m, "BYOD") + theme(legend.position = "none"),
   fn_bal(dta_m, "Ignore_warnning")+ theme(legend.position = "none"),
   fn_bal(dta_m, "Strong_pin") + theme(legend.position = "none"),
   fn_bal(dta_m, "Store_passwords")+ theme(legend.position = "none"),
   fn_bal(dta_m, "update_OS")+ theme(legend.position = "none"),
   fn_bal(dta_m, "public_WiFi") + theme(legend.position = "none"),
   fn_bal(dta_m, "Ignore_warnning")+ theme(legend.position = "none"),
   fn_bal(dta_m, "unsecured_network") + theme(legend.position = "none"),
   fn_bal(dta_m, "network_control")+ theme(legend.position = "none"),   
   fn_bal(dta_m, "network_attack")+ theme(legend.position = "none"),
   fn_bal(dta_m, "encrypted_transimittion") + theme(legend.position = "none"),
   fn_bal(dta_m, "unreliable_int")+ theme(legend.position = "none"),
   fn_bal(dta_m, "cloud_resource") + theme(legend.position = "none"),
   fn_bal(dta_m, "cloud_compute")+ theme(legend.position = "none"),
   fn_bal(dta_m, "remote_datastore")+ theme(legend.position = "none"),
   fn_bal(dta_m, "Data_regulation") + theme(legend.position = "none"),
   fn_bal(dta_m, "multiple_login")+ theme(legend.position = "none"),
   fn_bal(dta_m, "unknown_app") + theme(legend.position = "none"),
   fn_bal(dta_m, "update_ES")+ theme(legend.position = "none"),   
   fn_bal(dta_m, "Auto_update")+ theme(legend.position = "none"),
   fn_bal(dta_m, "VPN") + theme(legend.position = "none"),
   fn_bal(dta_m, "third_party_app")+ theme(legend.position = "none"),
   fn_bal(dta_m, "single_authenticate") + theme(legend.position = "none"),
   fn_bal(dta_m, "audit_log")+ theme(legend.position = "none"),
   fn_bal(dta_m, "access_right")+ theme(legend.position = "none"),
   fn_bal(dta_m, "change_data") + theme(legend.position = "none"),
   fn_bal(dta_m, "malicious_attack")+ theme(legend.position = "none"),
   fn_bal(dta_m, "Data_threats") + theme(legend.position = "none"),
   fn_bal(dta_m, "weak_authentication")+ theme(legend.position = "none"),  
   nrow = 6, ncol=5
)

  
```



## T-test

The t-test is used to compare the sample mean of our Treated group and Control group. The goal is to determine whether the intervention has an effective effect on the treated group. Our hypothesis is the intervention will have positive impact towards the restaurant's revenue . The t-test results is represented in the table xxx. The package **Broom** [@broom1] is used to clean the t test results and convert it into the dataframe. The p value we get is < 2.2e-16, as the p value would indicate a significant result, meaning that the actual p value is even smaller than 2.2e-16 (a typical threshold is 0.05, anything smaller counts as statistically significant). So we can 
interpret hypothesis not rejected which means that the re-opening of restaurants has a significant effect on treated group in terms of revenue increase.




## correlation model


## regression model 
We are using RStudio to run the multiple linear regression model. The following reasons explain why we decide to choose multiple linear regression [@WinNT]:

* It account for all of the potentially important factors in one model
* It leads to a more precise understanding of the relationship between dependent variables and independent variables
* It is able to identify outliers or anomalies in the dataset. 



**R squared** : 

R-squared  is a measure of the goodness of fit of the model. A larger R-squared  indicates a closer fit of the model to the data. It is used as an optimality criterion in parameter selection and model selection [@johansen1980welch].

**P-value**:

P-value is used to describe the occurrence possibility of the extreme outcome when the null hypothesis is true [@ioannidis2018proposal]. If the p-value is small, it means that the probability of occurrence of the null hypothesis to be true is very small. And if it does occur, we have a reason to reject the null hypothesis. In short, the smaller the p-value, the more significant the result. Usually the threshold for significant p value is set to 0.05.

**Regression coefficient**:

The sign of the regression coefficient describes whether there is a positive or negative correlation between each feature variable and the dependent variable (Warren affective score). A positive coefficient means that as the value of the independent variable increases, the average value of the affective score also tends to increase. A negative coefficient indicates that as the independent variable increases, the affective score tends to decrease [@uyanik2013study].





# Results

# Discussion

## Causality 

## First discussion point

## Second discussion point

## Third discussion point

## Weaknesses and next steps

The true propensity score is never known in observational studies, so you can never be certain that the propensity score estimates are accurate. Some authors urge caution in knowing the limitations of what really amounts to an estimation tool — and trying to approximate a random experiment from observational data can be fraught with pitfalls. Others, (e.g. King,2016) think that these scores shouldn’t be used for matching at all.

\newpage

\appendix

# Appendix {-}


# Additional details


\newpage


# References


