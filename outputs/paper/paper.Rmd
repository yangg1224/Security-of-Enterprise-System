---
title: "Are iPhone users more secure when using mobile enterprise systems?"
subtitle: "The difference of the perceived security of Enterprise Systems between IOS and Android users"
author: "Yang Wu"
header-includes:
 - \usepackage{float}
 - \floatplacement{figure}{H}
 - \floatplacement{table}{H}
thanks: "Code and data are available at: https://github.com/yangg1224/Security-of-Enterprise-System.git."
date: "`r format(Sys.time(), '%d %B %Y')`"
abstract: "Organizations are adopting mobile technologies for various business applications including Enterprise system (ES) to increase the flexibility and to gain sustainable competitive advantage. At the same time, end-users are exposed to security issues when using mobile technologies. Users’ usage habits and users’ attitudes towards those potential security issues would have a significant impact to the perceived security of ES. Here comes the question: will iPhone users have higher perceived security than Android users? Through the propensity score matching and regression model, we have the answer. \\par \\textbf{Keywords:} Security Issues; Perceived security measurement; iPhone & Android; Matching "

output:
  bookdown::pdf_document2:
toc: TRUE
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tinytex)
library(tidyverse)
library(palmerpenguins)
library(ggplot2)
library(ggthemes)
library(ggpubr)
library(hrbrthemes)
library(kableExtra)
library(broom)
library(randomForest)
library(plyr)
library(qqplotr)
library(dplyr)
library(gridExtra)
library(huxtable)

```

# Introduction
Mobile Enterprise System (ES) has more unique advantages than traditional enterprise systems. With a mobile enterprise platform, the entire company can be moved to the internet. Therefore, users who have permission can remotely access the enterprise database with any device equipped with a browser. Easy and convenient accessibility of data from mobile devices anywhere and anytime has made a significant change in people’s working style [@al2011preliminary]. People are no longer confined to working in the office, and any place can be their workstation. Besides, increasing business applications take advantage of mobile devices features such as a touchscreen, camera, video, voice, and other advanced functions to maximize the productivity. [@rodrigues2021mediation].


These advantages have created a vulnerability. The primary design purpose for the mobile device is its portability, not its security, which gives mobile enterprise systems weaker defense capabilities (He, 2013). There are many challenges and issues stemming from a lack of users’ awareness and negative attitudes. It is increasingly hard for an enterprise to maintain resource safety since the interaction between the user and device boost sharply. The features of these interactions are often unplanned and lack of supervision, which makes the leakages of the enterprise information possible[@matkerimov2020ways].


The dependent variable in my project is the perceived security of mobile ES. Many researchers have widely discussed the definition of mobile ERP system security. Although their understanding of the ERP security is strongly based on their speciﬁc domains, some aspects of the understanding of mobile ERP security are shared. [@siponen2007review] define security as the protection of resources to attain the objectives of integrity, availability, and conﬁdentiality. With regards to “integrity”, the authors suggest the metadata cannot be modified without authorization, while “availability” means that authorized person can access information anytime and anywhere. Finally, “confidentiality” refers to certain actions being implemented to prevent information leakage.


As we all know, compared with Android devices, iPhone has relatively closed platform, which gives it higher security performance. But users’ usage habits also have a huge impact towards the perceived security. For example, if users tend to use public Wi-Fi at coffee shop, the perceived security of ES would be lower. Because the system has more risk of information leakage. (whether they update operating system; how they deal with pop up security warning ...) All those uncertainties raise my interest to figure it out.  


The purpose of this project is to examine whether iPhone users (IOS) are securer than Android users when using mobile ES. The intervention is using iPhone as mobile device. The questionnaire survey is the chosen method for collecting data from mobile ES users, which has been done last year.  **propensity score matching** will be used to avoid selection bias and evaluate the effect of the treatment by comparing the treaded and non-treated group. It allows me to easily consider many independent variables at once, and it can be constructed using logistic regression. Multiple regression will also be used to examine the impact of users’ attitudes towards perceived ES security. The research finding will help the security providers of ES to know the determinants of perceived security in the users’ perspectives and to take measures to improve the determinants.


The remainder of the paper is constructed as follows. Section 2 describes the dataset, data collection, and exploratory data analysis on feature visualization. Section 3 outlines the data analysis models, which is designed to discover relationships between features and the target variable. Section 4 summarizes the model results according to evaluation criteria. Finally, Section 5 discusses the research findings and provides directions for future research.


This paper uses R statistical programming language [@citeR]. In particular, we use packages `tidyverse` [@tidyverse],  `here` [@citehere], `ggpubr` [@citeggpubr] to manipulate data and packages, `kableExtra` [@citekableExtra] to generate tables, and `ggplot2` [@citeggplot], `ggthemes` [@citeggthemes] to adjust diagrams themes. 

# Data

## Intervention 

To accomplish the research objectives, the author did a literature review on perceived security of mobile Enterprise System (ES). Based on the current research findings, the author concludes that there are five main categories of security issues when using mobile ES, which are mobile device issues, wireless network issues, cloud computing issues, application-level issues, and data access level issues. Different mobile phone users would have different attitudes and usage habits towards those five areas security issues, which greatly affect the perceived security of the ES. In order to test how different those impact on the iPhone and Android users, the author plan to divide people into two groups. The intervention of this research is using iPhone as mobile device. The treated group will be people who use iPhone (IOS) to operate the ES, and people in the control group will be those who use Android (Huawei, Samsung, Mi, and so on).

## Data collection

An online questionnaire survey is the chosen method for collecting data from Mobile ES users. Compared with other methods, the major advantages of the online questionnaire are saving time, money, and manpower. Considering this research need to do a large quantity of data collection, the questionnaire is the only suitable method. The author conducted the online questionnaire survey one year ago under the guidance of the research method class. 


Through the agency of Chinese online questionnaire platform ‘Wenjuan Xing’ and the researcher’s personal relationship with certain companies, the author sends out around 800 online questionnaires randomly and 240 personal administered questionnaires. The personally administered survey is useful to increase the response rate and to enhance the data quality. The email reminders were sent for every ten days to encourage the potential participants to fill in their responses. 

## Questionnaire design and sample

The respondents were asked to do a demographics survey which includes age, gender, occupation, years of experience, name of the ES systems used, functions or modules of Mobile ES, Brand of the mobile devices used to access the ES, and ownership of the device. The questionnaire also has items for measuring users’ attitudes and usage habits on various security issues and perceived security of ES mobility. The data features part will describe more about it.  The data was collected by using an interval scale (0-strongly disagree to 10-strongly agree). The collected data was used for calculating the measures of central tendency (e.g. arithmetic mean), validating the hypotheses by using correlation, propensity score matching, multiple regression and other statistical analysis. 


By the end of the survey period, data had been collected from 344 participants. As a result, the overall response rate is 33%. Among 344 responses, 13 responses were rejected on account of too much missing data. Therefore, 331 useable online questionnaire data were obtained and used for data analysis. 

The screen shots of the questionnaire will be attached in the Appendix 1. 


## Dataset features

### Demographics features
Overall, the dataset has 331 observations and contains 50 features. The first nine features describes users' demographic information. 

* `Work_experience` : measures how long does the user work in the current company 
* `Gender` : describes the user's gender 
* `Age` : describes the user's age
* `Education_level` : describes user's educational level (High school, college, undergrad, postgrade) 
* `Functions_used` : asks users which functionalities they use everyday
* `Usage_frequency` : describes the frequency of the usage of mobile ES
* `ES_Name` : describes the name of ES
* `Mobile_device` : asks for user's mobile phone brand 
* `Device_ownership` : clarify if the mobile phone is owned by company or owned by the user 

### perceived ES security features 

The perceived ES security is this paper's dependent variable. According to [@ertaul2005enterprise], enterprise security plan serves as an essential role to coordinate information security policies and applicable security technologies, making them align with the business rules and the developing information models and technical architectures. [@consoli2012corporate] combined acknowledged definitions of context and security, and concluded the security context should point to five goals:Integrity to ensure that data is in the original format and not modified; Confidentiality to ensure that only authorized people have access to resources; Authentication for allowing the access to the resources; Availability to maintain the proper functioning of the information system; Non-repudiation to ensure that a transaction cannot be denied.

According to the definition above, the dataset has five features to measure the perceived ES security. Starting from here, the questionnaire is designed using interval scale (0-strongly disagree to 10-strongly agree). The user is asked to give a number between 0 and 10, which represent for their attitudes towards the given situation. 

* `system_integrity` : measures user's attitude towards "I believe the data/ information in the mobile enterprise systems cannot be modified by unauthorized users"
* `system_availability` : measures user's attitude towards "I believe the data/ information in the mobile enterprise systems is available only to authorized users when required "
* `system_confidentiality` : measures user's attitude towards "I believe that the mobile enterprise systems are secured as the system detects and prevents the improper disclosure/ leakage of information"
* `system_accountability` : measures user's attitude towards "I believe that the mobile enterprise systems are secured as the system accounts the data changes"
* `system_nonrepudiation` : measures user's attitude towards "I believe that the mobile enterprise system is secured as the system does not deny any transaction that was carried out"
* `PSave` : (Dependent variable) used in the model. It takes a mean of the previous five features and presents for the user's perceived ES security. 

### Molibe device security issue features 

A mobile device refers to any portable device which has computing and storage capabilities [@singh2016framework]. The range of devices from smartphones, iPads, and tablets is quite popular among clients and IT professionals. Mobile users can work everywhere without being constrained by any networking system. These mobility and roaming features extend the network boundary beyond a single fixed point but make security management a much harder issue, because users cannot be tracked down into a fixed location anymore [@singh2016framework]. Moreover, mobile devices’ operational systems are highly vulnerable, which results in threats having a variety of ways to spread. There is no device whose platform is completely closed, which has weakened the security performance of the original application and creates more risks for information sharing[@hermann2014comparison].  There are six independent variables which might affect the perceived ES security:

* `Install_firewall` : measures user's attitude towards " I feel painful to install or update the security software such as antivirus and firewall software on my device."
* `BYOD` : measures user's attitude towards " I like the idea of using my own device for personal and corporate business."
* `Ignore_warnning` : measures user's attitude towards " I like to install applications in my mobile device without paying attention to permission warnings (or terms and conditions of usage)."
* `Strong_pin` : measures user's attitude towards " I feel painful to use a password or a pin code to lock my mobile device."
* `Store_passwords` : measures user's attitude towards " I feel it is simple and easy to store usernames and passwords on the device."
* `update_OS` :measures user's attitude towards " I feel painful to update the operating systems (e.g. iOS, Android) in my mobile device. "

### Wireless network security issue features 

Mobile communication is generated mainly through radio signals rather than wires, so mobile ES has particular challenges compared with traditional computer-based ES. First of all, reliable Internet availability is a pre-requirement for the secure wireless network. According to [@hermann2014comparison], “the wireless network is more accessible to intercept and attack, so traditional security technologies such as firewalls, authentication servers, biometrics, cryptography, intrusion detection, and VPNs are not enough to address security issues in the wireless network”[@hermann2014comparison]. There are six independent variables related to the wireless network which might affect the perceived ES security:

* `public_WiFi` : measures user's attitude towards "  I believe it is secured to use the wireless networks in public places such as coffee shops, airport kiosks, or other hotspots"
* `unsecured_network` : measures user's attitude towards " I show no interest on the security threats on the wireless networks."
* `network_control` : measures user's attitude towards " I feel nervous to know the enterprise doesn’t have much security control over the wireless networks."
* `network_attack` : measures user's attitude towards " I feel nervous to know that the hacker needs only a mobile device and a wireless card to capture data packets and transmission of the data."
* `encrypted_transimittion` : measures user's attitude towards " I believe the wireless network is not secured enough when the transmitted information is not encrypted."
* `unreliable_int` :measures user's attitude towards " I believe the data security and protection may be compromised when the Internet connection is not available and reliable. "

### Cloud Computing Security Issue features

The appearance of cloud computing is narrowing down the gap between mobile ES and small to medium companies. Although it does cut down the set-up process time and cost and reduces the required skills in the company, some challenges and problems should still be kept in mind. Certain loopholes in its architecture have made cloud computing vulnerable to various security and privacy threats [@picek2017acceptance].There are six independent variables related to the cloud computing which might affect the perceived ES security:

* `cloud_resource` : measures user's attitude towards "I believe that the applications that use cloud resources are vulnerable to threats."
* `cloud_compute` : measures user's attitude towards "I believe the cloud computing is vulnerable for data security since the access can be
interrupted at multiple points in the cloud."
* `remote_datastore` : measures user's attitude towards "Since the data is stored and processed remotely in cloud computing, I believe that the true ownership of the data becomes a security issue."
* `Data_regulation` : measures user's attitude towards "Since the data can be located anywhere in the world with different control and privacy regulations, I believe this practice leads to security risks."
* `multiple_login` : measures user's attitude towards " In a cloud environment, I like to logon to the same application using multiple devices simultaneously."
* `weak_authentication` :measures user's attitude towards "In a cloud environment, I like to use simple and short passwords."

### Application level security issue features
The application-level mobile solution mainly consists of mobile operation systems and mobile applications. The application layer provides users with an interface to operate their mobile devices. The operation system act as a platform to run mobile applications. Application-level issues usually take place in a multi-tenant environment or in a virtualized world[@hermann2014comparison]. There are six independent variables related to the application which might affect the perceived ES security:

* `unknown_app` : measures user's attitude towards "I feel pleasant to download applications from unreliable web sites or from links within e-mails"
* `update_ES` : measures user's attitude towards "I believe in installing updates for ERP systems to avoid any outdated security protections."
* `Auto_update` : measures user's attitude towards " I like to use automatic updater which applies any software application updates whenever available."
* `VPN` : measures user's attitude towards "I like to use VPN connections to download applications"
* `third_party_app` : measures user's attitude towards " I believe more fake apps/ malware versions (for Android) are found on third-party
application sites."
* `update` :measures user's attitude towards "I like to update the device operating systems and applications when prompted."

### Data Level Security Issue features
Since there is currently no appropriate regulation around data protection, data-level security is relying heavily on trust between the business and the provider. Data location and replication is one of the biggest concerns in the data level. A replica might be located in different countries where there is no clear legislation about data security and privacy, increasing the difficulty of managing the data [@kouatli2014comparative]. There are six independent variables related to the data access which might affect the perceived ES security:

* ` single_authenticate` : measures user's attitude towards "I like single authentication process for data access using only passwords."
* `audit_log` : measures user's attitude towards "I dislike maintaining audit logs to track any changes in the data.."
* `access_right` : measures user's attitude towards "I feel comfortable to give access rights to access all information to all employees"
* `change_data` : measures user's attitude towards " I feel comfortable to give permission to change all information by all employees"
* `malicious_attack` : measures user's attitude towards " I believe hackers can harvest user information from mobile ES and create malicious content to fraud the individual user"
* `Data_threat` :measures user's attitude towards "I believe anytime and anywhere data access with ES mobility brings a large number of data security threats."

## Descriptive Analysis 
```{r ,echo=FALSE}
####read the clean data 
clean_data<- read.csv(here::here("inputs/DATA/processed_dataset.csv"))
```


### Treat distribution 
From Figure \@ref(fig:treat) , we can clearly see that the iPhone user takes the lead and follows by HuaWei phone’s user. One reason why iPhone is so popular is that The iPhone ensures all apps and functions are performing the way Apple intended them to perform, which allows for a very simple user experience. As we know, iPhone devices use IOS operation system, while other type of devices are mostly using Android operation system. So the the author category all the users into two groups, one is using IOS and the other one is using Android. The second graph shows a balanced state between all the respondents. 

```{r treat, fig.cap = "device used by the respondents",echo=FALSE, warning= FALSE,fig.width=10, fig.height=6}

EDA<-clean_data

device_map <- 
  EDA%>%
  ggplot(aes(x = Mobile_device, fill = Mobile_device)) +
  geom_bar(width = 0.7,position = "dodge") + 
  coord_polar()+
  labs(title = "Device used by the respondents",x="", y="Count") +
  theme_minimal()

EDA$treat<-sapply(EDA$treat, as.factor)

# Create treat map data.
#table(EDA$treat)
data <- data.frame(
  category=c("treat(IOS)", "control(Android)"),
  count=c(163, 168)
)

# Compute percentages
data$fraction <- data$count / sum(data$count)

# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)

# Compute the bottom of each rectangle
data$ymin <- c(0, head(data$ymax, n=-1))

# Compute label position
data$labelPosition <- (data$ymax + data$ymin) / 2

# Compute a good label
data$label <- paste0(data$category, "\n value: ", data$count)

# Make the plot
treat_map<-
  ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=category)) +
  geom_rect() +
  geom_label( x=3.5, aes(y=labelPosition, label=label), size=6) +
  scale_fill_brewer(palette=1) +
  coord_polar(theta="y") +
  xlim(c(2, 4)) +
  theme_void() +
  theme(legend.position = "none")

# combine two diagram in one graph
ggarrange(
  device_map, treat_map,
  ncol = 2, nrow = 1,
  hjust = -0.5,
  align = "hv"
  )
```



### Demographics of user's work experience
Figure \@ref(fig:workexperience) demonstrates questionnaire respondents' work experience between treat group and control group. The red histogram represents people who use Android and the yellow histogram stands for iPhone users group. Working experience is an important element which might affect users' usage habits. The more professional they are, the more knowledge and experience they would have. Overall, we can see a relatively balanced match between iPhone and Android users. Most participants are holding three to five years working experience. It is interesting to find participants who has less than one year working experience like to use iPhone, while those with more than six year experience prefer to use Android. In terms of consistency, every iPhone works the same, while every Android works differently. Maybe more professional people would like to customize their phone and have more power to control their device. 


```{r workexperience, fig.cap = "Demographics of user's work experience",echo=FALSE, warning=FALSE,fig.width=10, fig.height=4}
edu <- 
  EDA%>%
  ggplot(aes(x = Work_experience,fill=treat, )) +
  geom_bar(position="dodge") +
  labs(title = "Demographics of user's work experience between treat and control group",x= "Work experience", y="Count")+
  scale_fill_manual(name = "Treat Group",values = c("#DB7558", "#FFCF57"))
edu
```

### Education level between treat and control group

Figure \@ref(fig:education) uses the jitter plot to visualize the distribution of education level by intervention groups. As we can see from the chart, people’s educational level is approximately at undergraduate and college. The iPhone user group is slightly more than Android user group in Master degree. But in general, there is not too much difference in terms of two group's educational level. 

```{r education, fig.cap = "Education level between treat and control group",echo=FALSE, fig.width=6, fig.height=3}

s1<-
  ggplot(EDA, aes(x = treat, y= Education_level,color=treat)) +
  geom_point(position = "jitter", alpha = 4/5)+
  labs(title="Education level between treat and control group", x="Intervention", y="Education level")+
  theme_light() + 
  scale_color_manual(name = "Treat group", values = c("#DB7558", "#FFCF57")) 
s1
```


### Device ownership 

Device ownership also plays an important role in security context.  Many employees bring their own device to the company for work and personal usage (bring your own device, BYOD), which is not trustworthy for enterprise system security [@souppaya2013guidelines]. As company has less control over employees’ device, they have rights to download any software or choose the security level of their mobile devices. Figure \@ref(fig:own) shows who own the device among 331 observations. We can find almost 95% devices are owned by the participants themselves. 

```{r own, fig.cap = "internet usages",echo=FALSE, fig.width=6.5, fig.height=4}
G1<-ggplot(EDA, aes(x=Device_ownership, fill=Device_ownership))+ 
    geom_bar(alpha=0.8 , size=0.2, colour="black", stat = "count")+
    labs(title = "User's Device ownership ",y="Counts",x="")

G1
```




# Model

The author made a choice between difference in difference method and propensity score matching method. Both methods are good for analyze observation data. The difference-in-difference method captures the significant differences in outcomes across the treatment and control groups, which occur between pre-treatment and post-treatment periods[@lechner2011estimation]. Difference in differences is a useful analysis framework to compare the changes in dependent variables, but in this project, it is hard to identify a certain time period. Because we cannot force our survey participants to use certain mobile devices in this period. Besides that, there might be a huge selection bias if we use DD method. Between iPhone and Android users, there would have lots of difference like their education level, age, gender, work experience and so on. It is really hard to match the people in the treat and control groups as closely as possible. Therefore, the author choose to use propensity score matching in this project.

## propensity score matching method

Propensity score matching estimators are widely used in evaluation research to estimate average treatment effects[@abadie2016matching]. Propensity score matching creates a group of participants for the treatment and control groups. The matching group consists of at least one participant in the treatment group with similar propensity scores and at least one participant in the control group. The goal is to approximate a random experiment and eliminate many problems caused by observational data analysis like selections bias.

## propensity score estimation 

Basically, the propensity score matching method would assign some probability to each observation. In this project, based on the independent variables (users’ attitudes towards different kind of security issues), the author constructs the propensity score estimation. We estimate the propensity score by running a logit model where the dependent variable (perceived ES security) is a binary variable indicating treatment status. **glm()** is used to fit generalized linear models, specified by giving a symbolic description of the linear predictor and a description of the error distribution[@glm]. Table \@ref(tab:pse) shows the results. We can then compare the outcomes of observations with similar propensity scores. 


```{r pse, fig.cap = "propensity score estimation table",echo=FALSE}

m_ps<-glm(treat~ Install_firewall+BYOD+ Ignore_warnning+Strong_pin+ Store_passwords+update_OS+public_WiFi+unsecured_network+ network_control+network_attack+encrypted_transimittion+unreliable_int+cloud_resource +cloud_compute+remote_datastore+Data_regulation+multiple_login+weak_authentication+unknown_app+ update_ES+ Auto_update+VPN + third_party_app+update+single_authenticate+audit_log+access_right+ change_data+ malicious_attack+Data_threats, 
family = binomial(), data = clean_data)

library(modelsummary)
ms<-
modelsummary(
m_ps,
output = "default",
fmt = 3,
estimate = "estimate",
statistic = "std.error",
vcov = NULL,
conf_level = 0.95, #confidence level to use for confidence intervals
stars = TRUE,
align = NULL,
notes = NULL,
title = "propensity score estimation table")
ms%>%
  kableExtra::kable_styling(bootstrap_options = "basic",
                            latex_options = "HOLD_position",
                            table.envir = "table",
                            font_size =5
                          )


```


Using this model, we can now calculate the propensity score for each ES user. It is simply the user’s predicted probability of being Treated, given the estimates from the logit model. Below, the author calculates this propensity score using **predict()** and create a dataframe that has the propensity score as well as the user’s actual treatment status. Table \@ref(tab:ps)  shows the first 6 rows of result. 
```{r ps, fig.cap = "ES user's propensity score",echo=FALSE }
##propensity score 
prs_df <- data.frame(pr_score = predict(m_ps, type = "response"),
                     treat = m_ps$model$treat)
m<-head(prs_df)

m%>%
  kableExtra::kbl(caption="ES user's propensity score and actual treatment status")%>%
  kableExtra::kable_styling(latex_options = c("hold_position"))
```

## Examing the Region of common support
After estimating the propensity score, it is useful to plot histograms of the estimated propensity scores by treatment status. As shown in Figure \@ref(fig:cs1), these graphics show the overlap of the propensity scores of the two groups, suggesting they share a lot of common support on the covariates in the model.

```{r cs1, fig.cap = "ES user's propensity score",echo=FALSE, warning=FALSE,fig.width=6.5, fig.height=4}


labs <- paste("Actual phone type used:", c("IOS", "Andriod"))
prs_df %>%
  mutate(treat = ifelse(treat == 1, labs[1], labs[2])) %>%
  ggplot(aes(x = pr_score)) +
  geom_histogram(color = "white", bins=30) +
  facet_wrap(~treat) +
  xlab("Probability of using iPhone to operate ES") +
  theme_bw()

```

Common support Figure \@ref(fig:cs2) indicates the regions of stratification share enough members of the treatment and control groups.

```{r cs2, fig.cap = "ES user's propensity score",echo=FALSE, warning=FALSE,fig.width=6.5, fig.height=4}


prs_df %>%
  mutate(treat = ifelse(treat == 1, labs[1], labs[2])) %>%
  ggplot()+
  geom_histogram(aes(x=pr_score, y=..density.., fill=treat), color="white", bins=30, position="identity", alpha=.3)+
  geom_density(aes(x=pr_score, color=treat))

```

## Executing matching algorithm 
**MatchIt** package [@match] is used here to find pairs of observations that have very similar propensity scores, but that differ in their treatment status. This package estimates the propensity score in the background and then matches observations based on the "nearest" method.

Note that the final dataset is smaller than the original: it contains 326 observations, meaning that 163 pairs of treated and control observations were matched. Also note that the final dataset contains a variable called distance, which is the propensity score.
```{r  ema, fig.cap = "ES user's propensity score",echo=FALSE, warning=FALSE,fig.width=6.5, fig.height=4}
library(MatchIt)

clean_data$treat<-sapply(clean_data$treat, as.factor)


mod_match <- matchit(treat~ Install_firewall+BYOD+ Ignore_warnning+Strong_pin+
                       Store_passwords+update_OS+public_WiFi+unsecured_network+
                       network_control+network_attack+encrypted_transimittion+unreliable_int+
                       cloud_resource +cloud_compute+remote_datastore+Data_regulation+multiple_login+
                       weak_authentication+unknown_app+  update_ES+ Auto_update+
                       VPN + third_party_app+update+single_authenticate+audit_log+access_right+ change_data+ malicious_attack +Data_threats, method = "nearest", data = clean_data)

## check the match
dta_m <- match.data(mod_match)


head(dta_m)%>%
  kableExtra::kbl(caption = "Head of raw matching dataset")%>%
  kableExtra::kable_styling(latex_options = "scale_down")%>% # use scale_down option to make the font
  kableExtra::kable_styling(latex_options = c("hold_position"))
```

## Model check---Examining covariate balance in the matched sample

The author uses visualization to show whether the matching is done well. The Figure \@ref(fig:balance) plots the mean of each independent variable against the estimated propensity score, separately by treatment status. If the matching result is good, the treatment and control groups will have similar identical means of each covariate at each value of the propensity score. In general, the model has a good match. 

```{r balance, fig.cap = "covariate balance check",echo=FALSE, warning=FALSE,fig.width=8, fig.height=10}

fn_bal <- function(dta, variable) {
  dta$variable <- dta[, variable]
  dta$treat <- as.factor(dta$treat)
  support <- c(min(dta$variable), max(dta$variable))
  ggplot(dta, aes(x = distance, y = variable, color = treat)) +
    geom_point(alpha = 0.2, size = 1.3) +
    geom_smooth(method = "loess", se = F,formula = y ~ x) +
    xlab("Propensity score") +
    ylab(variable) +
    theme_bw() +
    ylim(support)
}

 grid.arrange(
   fn_bal(dta_m, "Install_firewall")+ theme(legend.position = "none"),
   fn_bal(dta_m, "BYOD") + theme(legend.position = "none"),
   fn_bal(dta_m, "Ignore_warnning")+ theme(legend.position = "none"),
   fn_bal(dta_m, "Strong_pin") + theme(legend.position = "none"),
   fn_bal(dta_m, "Store_passwords")+ theme(legend.position = "none"),
   fn_bal(dta_m, "update_OS")+ theme(legend.position = "none"),
   fn_bal(dta_m, "public_WiFi") + theme(legend.position = "none"),
   fn_bal(dta_m, "Ignore_warnning")+ theme(legend.position = "none"),
   fn_bal(dta_m, "unsecured_network") + theme(legend.position = "none"),
   fn_bal(dta_m, "network_control")+ theme(legend.position = "none"),   
   fn_bal(dta_m, "network_attack")+ theme(legend.position = "none"),
   fn_bal(dta_m, "encrypted_transimittion") + theme(legend.position = "none"),
   fn_bal(dta_m, "unreliable_int")+ theme(legend.position = "none"),
   fn_bal(dta_m, "cloud_resource") + theme(legend.position = "none"),
   fn_bal(dta_m, "cloud_compute")+ theme(legend.position = "none"),
   fn_bal(dta_m, "remote_datastore")+ theme(legend.position = "none"),
   fn_bal(dta_m, "Data_regulation") + theme(legend.position = "none"),
   fn_bal(dta_m, "multiple_login")+ theme(legend.position = "none"),
   fn_bal(dta_m, "unknown_app") + theme(legend.position = "none"),
   fn_bal(dta_m, "update_ES")+ theme(legend.position = "none"),   
   fn_bal(dta_m, "Auto_update")+ theme(legend.position = "none"),
   fn_bal(dta_m, "VPN") + theme(legend.position = "none"),
   fn_bal(dta_m, "third_party_app")+ theme(legend.position = "none"),
   fn_bal(dta_m, "single_authenticate") + theme(legend.position = "none"),
   fn_bal(dta_m, "audit_log")+ theme(legend.position = "none"),
   fn_bal(dta_m, "access_right")+ theme(legend.position = "none"),
   fn_bal(dta_m, "change_data") + theme(legend.position = "none"),
   fn_bal(dta_m, "malicious_attack")+ theme(legend.position = "none"),
   fn_bal(dta_m, "Data_threats") + theme(legend.position = "none"),
   fn_bal(dta_m, "weak_authentication")+ theme(legend.position = "none"),  
   nrow = 6, ncol=5
)

  
```


## Estimating treatment effects---T-test

The t-test is used to compare the sample mean of our Treated group(IOS) and Control group(Android). The goal is to determine whether the intervention has an effective effect on the treated group. Our hypothesis is that the intervention will increase the perceived ES security. The t-test results will be presented in the next section. The package **Broom** [@broom1] is used to clean the t test results and convert it into the dataframe. 



## Estimating treatment effects---regression model 
We are using RStudio to run the multiple linear regression model. The following reasons explain why we decide to choose multiple linear regression to test the treatment effects [@WinNT]:

* It account for all of the potentially important factors in one model
* It leads to a more precise understanding of the relationship between dependent variables and independent variables
* It is able to identify outliers or anomalies in the dataset. 

**R squared** : 

R-squared  is a measure of the goodness of fit of the model. A larger R-squared  indicates a closer fit of the model to the data. It is used as an optimality criterion in parameter selection and model selection [@johansen1980welch].

**P-value**:

P-value is used to describe the occurrence possibility of the extreme outcome when the null hypothesis is true [@ioannidis2018proposal]. If the p-value is small, it means that the probability of occurrence of the null hypothesis to be true is very small. And if it does occur, we have a reason to reject the null hypothesis. In short, the smaller the p-value, the more significant the result. Usually the threshold for significant p value is set to 0.05.

**Regression coefficient**:

The sign of the regression coefficient describes whether there is a positive or negative correlation between each feature variable and the dependent variable (Warren affective score). A positive coefficient means that as the value of the independent variable increases, the average value of the affective score also tends to increase. A negative coefficient indicates that as the independent variable increases, the affective score tends to decrease [@uyanik2013study].





# Results

## Correlation matrix
Correlation matrix shows internal relationships between users' attitude feature variables and our variable of interest, perceived ES security. (Figure \@ref(fig:correlation)) Intensity and direction of relationship is indicated by the color scale from red to blue (+1 to -1. descendant).  Insignificant coefficient is barred with symbol "x". From the correlation matrix below, it is evident that the dependent variable (PSave) has secure connections with the independent variables. 

```{r correlation, fig.cap = "Correlation matrix",echo=FALSE, fig.width=11, fig.height=10}
#install.packages("fastDummies")
library(fastDummies)


# correlation matrix for restaurants in treated group
CM_data<-clean_data[-c(1:9,51)] 

# Compute a correlation matrix
corr <- round(cor(CM_data), 1) # round to 1 digit
# Compute a matrix of correlation p-values
#install.packages("ggcorrplot")

library(ggcorrplot)
p.mat <- cor_pmat(CM_data)
# Visualize the lower triangle of the correlation matrix
# Barring the no significant coefficient
ggcorrplot(
  corr, hc.order = TRUE, type = "lower",
  p.mat=p.mat,
  title = "Correlation Matrix"
  )
```

## Two-sample T-test results

### Average perceived ES security score

Table \@ref(tab:summary) shows some basic statistic analysis about iPhone group and Android group. The average perceived ES security for iPhone group is 5.082209. The average perceived ES security for Android group is 5.427381.

The standard error is considered part of inferential statistics. It represents the standard deviation of the mean within a dataset. This serves as a measure of variation for random variables, providing a measurement for the spread. The smaller the spread, the more accurate the dataset. The standard error is 0.1227353 for control group and 0.1076873 for treat group. 

```{r summary, fig.cap = "T-test",echo=FALSE, warning=FALSE,fig.width=8, fig.height=4 }


#### 1.1 Difference-in-means: dependent variable
clean_data%>%
  group_by(treat) %>%
  dplyr::summarise(n_users=n(),.groups = 'drop',
            mean_perceived_security= mean(PSave),
            std_error  = sd(PSave)/ sqrt(n_users))%>%
  kableExtra::kbl(caption = "Difference-in-means: dependent variable") %>%
  kableExtra::kable_styling(latex_options = c("hold_position"))



```


### T-test results

After propensity score matching, Table \@ref(tab:ttest) shows the t-test result. The p value we get is 0.073385, as the p value would indicate a significant difference between two groups (a typical threshold is 0.05, anything smaller counts as statistically significant). The 95% confidence interval shows that the true difference is between -0.0280458 and 0.6170028.

```{r ttest, fig.cap = "T-test",echo=FALSE, warning=FALSE,fig.width=8, fig.height=4}
## T test
ttest_after<-with(dta_m, t.test(PSave ~ treat))

tidy(ttest_after)%>%
  select(-c(estimate,statistic,parameter))%>%

  kableExtra::kbl(caption = "T-test on dependent variable") %>%  
  kableExtra::kable_styling(latex_options = "scale_down")%>% # use scale_down option to make the font
  kableExtra::kable_styling(latex_options = c("hold_position"))
```

## Model Results

Multiple linear regression was applied to predict the perceived ES security, using 30 independent variables and 1 1 dummy variable which indicate the intervention status.

### Treatment effect result
Table \@ref(tab:model1) shows the treatment effect. In this model result, the intercept (5.377) represents the average effect for the reference group. There is only one reference group : **Treat: treat 0 (using Android devices)**The coefficient for **treatment effect** is -0.294, suggesting that the average perceived security from people who use iPhone is on average 0.294 unit lower than those who use Android, holding other variables constant. The p value is 0.0734, which indicates this is a significant result.

```{r model1,fig.cap = "regression model result",echo=FALSE, warning=FALSE,fig.width=5, fig.height=8}
## regression 


propensity_score_regression1 <- lm(PSave~ treat,
                                  data = dta_m)
library(modelsummary)
ms<-
modelsummary(
propensity_score_regression1,
output = "default",
fmt = 3,
estimate = "estimate",
statistic = "std.error",
vcov = NULL,
conf_level = 0.95, #confidence level to use for confidence intervals
stars = TRUE,
align = NULL,
notes = NULL,
title = "Treatment effect")
ms%>%
  kableExtra::kable_styling(bootstrap_options = "basic",
                            latex_options = "HOLD_position",
                            table.envir = "table",
                            font_size =5
                       )

```


### regression model results

As shown in the summary table,Table \@ref(tab:model)^[The 'modelsummary' package @cite_modelsummary was helped to create the table.], there are 7 variables are significant (p<0.05) to the perceived ES security: update_OS; network_control; Data_regulation; weak_authentication; public_WiFi; Auto_update; malicious_attack.


The coefficient for **updata_OS** is 0.156, suggesting that one unit increase in updata_OS score is associated with 0.156 unit increase in the perceived ES security, holding other variables constant.The p value is 0.005613, which indicates this is a significant result.

The coefficient for **public_wifi** is 0.133, suggesting that one unit increase in public_wifi score is associated with 0.133 unit increase in the perceived ES security, holding other variables constant.The p value is 0.011162, which indicates this is a significant result.

The coefficient for **network_control** is 0.232, suggesting that one unit increase in network_control score is associated with 0.232 unit increase in the perceived ES security, holding other variables constant.The p value is 0.001147, which indicates this is a significant result.

The coefficient for **Data_regulation** is 0.307, suggesting that one unit increase in data regulation score is associated with 0.307 unit increase in the perceived ES security, holding other variables constant.The p value is 0.000398, which indicates this is a significant result.

The coefficient for **Auto_update** is 0.132, suggesting that one unit increase in Auto_update score is associated with 0.132 unit increase in the perceived ES security, holding other variables constant.The p value is 0.036760, which indicates this is a significant result.

The coefficient for **malicious_attack** is -0.303, suggesting that one unit increase in malicious_attack score is associated with 0.303 unit decrease in the perceived ES security, holding other variables constant.The p value is 0.000902, which indicates this is a significant result. 

The coefficient for **weak_authentication** is -0.155, suggesting that one unit increase in weak_authentication score is associated with 0.155 unit decrease in the perceived ES security, holding other variables constant.The p value is 0.021122, which indicates this is a significant result. 






```{r model,fig.cap = "regression model result",echo=FALSE, warning=FALSE,fig.width=5, fig.height=8}
## regression 


propensity_score_regression <- lm(PSave~ Install_firewall+BYOD+ Ignore_warnning+Strong_pin+
                                    Store_passwords+update_OS+public_WiFi+unsecured_network+
                                    network_control+network_attack+encrypted_transimittion+unreliable_int+
                                    cloud_resource +cloud_compute+remote_datastore+Data_regulation+multiple_login+
                                    weak_authentication+unknown_app+  update_ES+ Auto_update+
                                    VPN + third_party_app+update+single_authenticate+audit_log+access_right+ change_data+ malicious_attack +Data_threats,
                                  data = dta_m)

propensity_score_regression1 <- lm(PSave~ treat,
                                  data = dta_m)



library(modelsummary)
ms<-
modelsummary(
propensity_score_regression,
output = "default",
fmt = 3,
estimate = "estimate",
statistic = "std.error",
vcov = NULL,
conf_level = 0.95, #confidence level to use for confidence intervals
stars = TRUE,
align = NULL,
notes = NULL,
title = "Regression results summary table")
ms%>%
  kableExtra::kable_styling(bootstrap_options = "basic",
                            latex_options = "HOLD_position",
                            table.envir = "table",
                            font_size =5
                       )

```

The summary table above shows that the R-square value for the multiple linear regression model is 0.626, which means about 62.6% of the variation in the dependent variable(perceived ES security) can be explained by the multiple linear regression model. 


# Discussion

In a short conclusion, this research posts a question at the beginning: will iPhone user be more secure than Android user when using mobile enterprise system? To answer this question, the author did a literature review and category five main security issues when using mobile app. Based on that, the data was collected through the online questionnaire survey. The dataset was divided into two groups (IOS group and Android group), propensity score matching was applied to avoid selection bias. Though the treatment effect (iPhone as device) is not significant, we can not tell there is a strong evidence to support iPhone user is more secure than Android user when using mobile ES. The author still find something interesting about the dataset features. Through the multiple linear regression model, the author examined the impact of users’ attitude towards security issues on perceived security of ES mobility. The study findings will be used to evolve strategic considerations for designing and developing secured mobile ES. This will help the security providers of ES to know the determinants of perceived security in the users’ perspective and to take measures to improve the determinants.


## Causality 

Through the multiple linear regression, the treatment effect (treat1) is -0.294, which means using iPhone as device to operate enterprise system would be less secured than using Android. The p value is 0.07, which provide a strong evidence to support the regression result. Our guess that iPhone user would be more secured is rejected. In other word, using Android device would increase the perceived ES security. Android users have better awareness to defend different security issues. 

## Research findings
 
### Android user's average perceived ES security is higher! 

From the result of the two sample T test, we are amazed to find the score for Android user's average perceived ES security is around 6%  higher than iPhone user's score. The sample distribution shows employees who have more than 3 years working experience more inclined to use Android phones. While for those employees with less than 1 year working experience, they are the majority iPhone users. Android users has better awareness towards the security issues might have the following reasons:  Apple think what is the best for you, and no matter what you need or not. So iPhone locks down the UI and system setting, which greatly limit the customization. In contrast, users can make their Android phone unique! With deep knowledge, users can make their Android phone more secured.   


### Wireless network security issues have the most critical impact 
According to the multiple linear regression model result, the regression coefficients for "public_WiFi", and "network_control" are very significant,
indicating that users’ attitudes towards wireless network security issues have the most critical impact on the perceived system security. 

[@zissis2012addressing] explained that the perceived security of ES mobility refers to three fundamental properties: confidentiality, integrity, and availability. Each of the three dimensions would be attacked when mobile devices are connecting with the wireless network. Confidentiality attack happens when location-less hacker destroys or steals users’ information through the radio signals; integrity attack happens when a hacker compromises the wireless network to modify, exchange or retransmit enterprise data; and availability attack happens when service availability is disrupted [@leung2007security].


Compared with the wired network, the wireless context is more vulnerable to be hacked because the transmission method of the radio signal is exposed to the air and could be intercepted anytime and anywhere. Besides, the wireless network is usually provided by a private service provider and operated on public shared infrastructure. The majority of small to medium enterprises do not have rights to control or manage the wireless network security setting, and they also lack of knowledge about security of the network infrastructure [@zissis2012addressing].
After analyzing the implications of finding, the following best practices for addressing users’ attitudes towards wireless network security issues are listed:

* Do not use public Wi-Fi to operate any mobile Enterprise system (such as Wi-Fi in coffee shops, airport kiosks or other hotspots).
* Pay attention to wireless network security warnings that pop up on mobile devices
* Keep your web browser, wireless firewall, and anti-virus software up to date.

### Business need a strategic level security plan toward ES mobility

Through the demographics of ownership of the device, it is notable to find that 93 percent of mobile devices are owned by users. “Bring your own device” (BYOD) issues increase the risk of data breaches because the portable devices are easy to get lost or stolen [@he2013survey]. Besides, when employees leave the organization, they are no longer under the protection of the company’s network’s firewall. However, the company’s confidential data is still stored in that device. Accordingly, BYOD will increase the possibility of data leaking, and it is more vulnerable for malicious threats. Companies can cause security crises if their employees lack an understanding of the different changes in the enterprise security environment. Many mobile users overly trust the security of their device and often ignore security alerts. For example, many users do not care about the permission warnings before installing the applications[@he2013survey]. Based on that, the author put  forwards the following advice:

* It is vital for any business to have a strategic level security plan toward ES mobility.
* Pay attention to permission warnings (or terms and conditions of usage) when installing the applications
* The mobile ES user should involve themselves in developing an enterprise-level security plan and understand how it works.


## Weaknesses and next steps

### potential limitations 

First, there are a considerable number of mobile ERP users distributed all over the world. However, the questionnaire survey in this study was only carried out in China. In addition, the sample overrepresents the female perspective (57%) and the perceptive of the iPhone mobile user (53%). The sample is not entirely representative of the wide range of mobile ES users. These limitations could bias the results of the data analysis. 

Second, the number of respondents for the questionnaire survey is not large enough, which might lower the universality of the research results. 

Third, this study uses the online questionnaire as its method to collect data, and the accuracy and quality of the data cannot be guaranteed because of participants’ perfunctory responses.

Fourth, The true propensity score is never known in observational studies, so you can never be certain that the propensity score estimates are accurate [@abadie2016matching]. Some authors urge caution in knowing the limitations of what really amounts to an estimation tool, they mentioned that "trying to approximate a random experiment from observational data can be fraught with pitfalls" [@caliendo2008some]. 


### Future research direction 

This research aims to find how different iPhone users act compared with Android users, and how those actions or awareness impact the perceived ES security. Unfortunately, the treatment effect is not obvious. 

This study also focuses on users’ attitudes on the perceived security of enterprise systems mobility. In order to enhance the security of mobile ERP software, IT developers are also essential for system maintenance. Future research could study how to increase system security and reduce risks from the perspective of IT staff. 

The data collection can be done in the perspective of IT staff and top management. In addition, to avoid limitations on the sample, the future researchers can consider carrying out investigations with respondents from a broader scope and more diverse backgrounds, which can help enhance the universality and quality of the data collection.

\newpage

\appendix

## Appendix A 
The data collection was done in China, so the language is Chinese. Here is the link: https://www.wjx.cn/jq/43537868.aspx 

```{r page1, echo=FALSE, fig.cap="Screen capture of the first part of the Survey.", out.width = '70%', fig.align="center"} 
knitr::include_graphics(here::here("outputs/paper/image/image1.png"))
```

## Appendix B 
The first 100 rows of raw data which will be used in regression is shown in the Table below. (Table \@ref(tab:rowdata))
```{r rowdata, echo=FALSE}
  head(clean_data,100)%>%
  kableExtra::kbl(caption = "First 100 rows Raw data ") %>%
  kableExtra::kable_styling(latex_options = "scale_down")%>% # use scale_down option to make the font
  kable_styling()
```
\newpage


# References


